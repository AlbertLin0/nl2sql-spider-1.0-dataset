{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c9a3040",
   "metadata": {},
   "source": [
    "# 删除库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "737611a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "subdir = [\n",
    "    # \"aan_1\",\n",
    "    # \"address_1\",\n",
    "    # \"boat_1\",\n",
    "    # \"online_exams\",\n",
    "    # \"video_game\",\n",
    "    # \"government_shift\",\n",
    "    # \"planet_1\",\n",
    "    # \"warehouse_1\",\n",
    "    # \"book_press\",\n",
    "    # \"district_spokesman\",\n",
    "    # \"restaurant_bills\",\n",
    "    # \"soccer_3\",\n",
    "    # \"tv_shows\",\n",
    "    # \"institution_sports\",\n",
    "    # \"car_road_race\",\n",
    "    # \"bakery_1\",\n",
    "    # \"bbc_channels\",\n",
    "    # \"region_building\",\n",
    "    \"cre_doc_workflow\",\n",
    "    # \"pilot_1\",\n",
    "    # \"country_language\",\n",
    "    # \"club_leader\",\n",
    "    # \"cre_doc_and_collections\",\n",
    "    # \"book_1\",\n",
    "    # \"cre_students_information_systems\",\n",
    "    # \"customers_and_orders\",\n",
    "    # \"advertising_agencies\", \n",
    "    # \"university_rank\",\n",
    "    # \"sing_contest\",\n",
    "    # \"movie_2\",\n",
    "    # \"bike_racing\",\n",
    "    # \"e_commerce\",\n",
    "    # \"art_1\", \n",
    "    # \"real_estate_rentals\",\n",
    "    # \"book_review\",\n",
    "    # \"car_racing\",\n",
    "    # \"vehicle_driver\",\n",
    "    # \"headphone_store\",\n",
    "    # \"conference\",\n",
    "    # \"vehicle_rent\",\n",
    "]\n",
    "# subdir = [\n",
    "#     \"aan_1\",\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590b61bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "尝试终止所有连接到 spider1_0_cre_doc_workflow 的进程...\n",
      "连接终止完成。\n",
      "尝试删除数据库: spider1_0_cre_doc_workflow...\n",
      "✅ 数据库 'spider1_0_cre_doc_workflow' 成功删除。\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "\n",
    "# ... DB_CONFIG 应该连接到 'postgres' 数据库 ...\n",
    "\n",
    "def force_drop_database(db_name, config):\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = psycopg2.connect(**config)\n",
    "        conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # 1. 终止所有连接\n",
    "        terminate_query = f\"\"\"\n",
    "        SELECT pg_terminate_backend(pid)\n",
    "        FROM pg_stat_activity\n",
    "        WHERE datname = '{db_name}' AND pid <> pg_backend_pid();\n",
    "        \"\"\"\n",
    "        print(f\"尝试终止所有连接到 {db_name} 的进程...\")\n",
    "        cursor.execute(terminate_query)\n",
    "        print(\"连接终止完成。\")\n",
    "\n",
    "        # 2. 执行删除操作\n",
    "        drop_query = f\"DROP DATABASE {db_name};\"\n",
    "        print(f\"尝试删除数据库: {db_name}...\")\n",
    "        cursor.execute(drop_query)\n",
    "        print(f\"✅ 数据库 '{db_name}' 成功删除。\")\n",
    "\n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"❌ 删除数据库 '{db_name}' 失败: {e}\")\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "DB_CONFIG = {\n",
    "        \"host\": \"xxx\",\n",
    "        \"user\": \"postgres\",      # 替换为您的用户名\n",
    "        \"password\": \"xxx\",  # 替换为您的密码\n",
    "        \"port\": \"xxx\"               # 默认端口\n",
    "    }\n",
    "for i in subdir: \n",
    "     force_drop_database(f\"spider1_0_{i}\", DB_CONFIG)\n",
    "# 示例调用\n",
    "# force_drop_database(\"spider1_0_warehouse_1\", ADMIN_DB_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7d79ae",
   "metadata": {},
   "source": [
    "# 批量创建数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc0fd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "def create_db(database):\n",
    "    db_list = []\n",
    "    for i in database:\n",
    "        db_list.append(f\"spider1_0_{i}\")\n",
    "    # --- 1. 数据库连接配置 ---\n",
    "    DB_CONFIG = {\n",
    "        \"host\": \"xxx\",\n",
    "        \"database\": \"postgres\",  # 替换为您的数据库名称\n",
    "        \"user\": \"postgres\",      # 替换为您的用户名\n",
    "        \"password\": \"xxx\",  # 替换为您的密码\n",
    "        \"port\": \"xxx\"               # 默认端口\n",
    "    }\n",
    "\n",
    "    # --- 2. SQL 文件路径 ---\n",
    "    SQL_FILE_PATH = f\"_{database}-schema.sql\"  # 替换为您的 SQL 文件路径\n",
    "\n",
    "    def create_databases(db_list, config):\n",
    "        \"\"\"\n",
    "        连接到 PostgreSQL 管理数据库并批量创建新的数据库。\n",
    "        \"\"\"\n",
    "        conn = None\n",
    "        try:\n",
    "            # 1. 建立管理连接\n",
    "            print(f\"尝试连接到 PostgreSQL 服务器 ({config['database']})...\")\n",
    "            conn = psycopg2.connect(**config)\n",
    "            \n",
    "            # 2. 设置隔离级别为 AUTOCOMMIT\n",
    "            # CREATE DATABASE 命令不能在事务块中执行，必须使用 AUTOCOMMIT 模式。\n",
    "            conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "            cursor = conn.cursor()\n",
    "            print(\"连接成功，启用 AUTOCOMMIT 模式。\")\n",
    "            \n",
    "            # 3. 逐个创建数据库\n",
    "            for db_name in db_list:\n",
    "                # 确保数据库名称是安全的，防止 SQL 注入\n",
    "                # 这里简单使用字符串格式化，但 CREATE DATABASE 不能使用参数化查询\n",
    "                create_query = f\"CREATE DATABASE {db_name};\"\n",
    "                \n",
    "                try:\n",
    "                    print(f\"正在创建数据库: {db_name}...\")\n",
    "                    cursor.execute(create_query)\n",
    "                    print(f\"✅ 数据库 '{db_name}' 创建成功。\")\n",
    "                    \n",
    "                except psycopg2.errors.DuplicateDatabase:\n",
    "                    print(f\"⚠️ 数据库 '{db_name}' 已存在，跳过。\")\n",
    "                \n",
    "                except psycopg2.Error as e:\n",
    "                    print(f\"❌ 创建数据库 '{db_name}' 失败: {e}\")\n",
    "                    # 即使失败也继续尝试下一个数据库\n",
    "                    \n",
    "        except psycopg2.Error as e:\n",
    "            print(f\"\\n❌ 致命错误：无法连接到 PostgreSQL 服务器。请检查配置和凭证。\")\n",
    "            print(e)\n",
    "            \n",
    "        finally:\n",
    "            # 4. 关闭连接\n",
    "            if conn:\n",
    "                cursor.close()\n",
    "                conn.close()\n",
    "                print(\"\\n数据库连接已关闭。\")\n",
    "\n",
    "\n",
    "    create_databases(db_list, DB_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33fce711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "尝试连接到 PostgreSQL 服务器 (postgres)...\n",
      "连接成功，启用 AUTOCOMMIT 模式。\n",
      "正在创建数据库: spider1_0_cre_doc_workflow...\n",
      "✅ 数据库 'spider1_0_cre_doc_workflow' 创建成功。\n",
      "\n",
      "数据库连接已关闭。\n"
     ]
    }
   ],
   "source": [
    "create_db(subdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d51bda",
   "metadata": {},
   "source": [
    "# 提交脚本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d37ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "\n",
    "def commit(database):\n",
    "    database = f\"spider1_0_{database}\"\n",
    "    # --- 1. 数据库连接配置 ---\n",
    "    DB_CONFIG = {\n",
    "        \"host\": \"xxx\",\n",
    "        \"database\": database,  # 替换为您的数据库名称\n",
    "        \"user\": \"postgres\",      # 替换为您的用户名\n",
    "        \"password\": \"xxx\",  # 替换为您的密码\n",
    "        \"port\": \"xxx\"               # 默认端口\n",
    "    }\n",
    "\n",
    "    # --- 2. SQL 文件路径 ---\n",
    "    SQL_FILE_PATH = f\"{database}-schema.sql\"  # 替换为您的 SQL 文件路径\n",
    "\n",
    "    def execute_sql_file():\n",
    "        conn = None\n",
    "        try:\n",
    "            # 连接到 PostgreSQL 数据库\n",
    "            print(f\"尝试连接到数据库: {DB_CONFIG['database']}...\")\n",
    "            conn = psycopg2.connect(**DB_CONFIG)\n",
    "            conn.autocommit = False  # 禁用自动提交，以实现事务控制\n",
    "            cursor = conn.cursor()\n",
    "            print(\"连接成功。\")\n",
    "\n",
    "            # 读取 SQL 文件内容\n",
    "            print(f\"读取 SQL 文件: {SQL_FILE_PATH}...\")\n",
    "            with open(SQL_FILE_PATH, 'r', encoding='utf8') as f:\n",
    "                # PostgreSQL 的 psycop2 驱动不能像 MySQL 一样直接处理多条语句\n",
    "                # 我们需要将文件内容拆分成单条命令\n",
    "                sql_commands = f.read()\n",
    "\n",
    "            # 使用 split() 方法按分号 ; 拆分命令，并过滤掉空行\n",
    "            # 注意：这假设您的 SQL 文件中的每条命令都以 ; 结束\n",
    "            commands = [cmd.strip() for cmd in sql_commands.split(';') if cmd.strip()]\n",
    "\n",
    "            print(f\"找到 {len(commands)} 条 SQL 命令，开始执行...\")\n",
    "\n",
    "            # 逐条执行 SQL 命令\n",
    "            for command in commands:\n",
    "                # 过滤掉注释行\n",
    "                if command.upper().startswith('--') or command.upper().startswith('/*'):\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    # 打印正在执行的命令（仅打印前100字符）\n",
    "                    print(f\"执行: {command[:100]}...\")\n",
    "                    cursor.execute(command)\n",
    "                    \n",
    "                except psycopg2.Error as e:\n",
    "                    # 如果某条命令失败，打印错误并继续或中止（取决于需求）\n",
    "                    print(f\"❌ 命令执行失败: {e.diag.message_primary}\")\n",
    "                    # 默认行为：遇到错误则抛出异常，触发 finally 中的回滚\n",
    "\n",
    "            # 提交事务\n",
    "            conn.commit()\n",
    "            print(\"\\n✅ 所有 SQL 命令在一个事务中成功执行并提交。\")\n",
    "\n",
    "        except psycopg2.OperationalError as e:\n",
    "            print(f\"\\n❌ 连接或操作失败: {e}\")\n",
    "            print(\"请检查数据库配置、服务状态和网络连接。\")\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"\\n❌ 错误: 找不到 SQL 文件 {SQL_FILE_PATH}，请检查路径。\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ 发生意外错误: {e}\")\n",
    "            if conn:\n",
    "                conn.rollback()  # 遇到任何错误都回滚事务\n",
    "                print(\"事务已回滚。\")\n",
    "\n",
    "        finally:\n",
    "            # 关闭数据库连接\n",
    "            if conn:\n",
    "                cursor.close()\n",
    "                conn.close()\n",
    "                print(\"数据库连接已关闭。\")\n",
    "\n",
    "\n",
    "    execute_sql_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b985d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "尝试连接到数据库: spider1_0_cre_doc_workflow...\n",
      "连接成功。\n",
      "读取 SQL 文件: spider1_0_cre_doc_workflow-schema.sql...\n",
      "找到 9 条 SQL 命令，开始执行...\n",
      "执行: CREATE TABLE \"authors\" (\n",
      "  \"author_name\" varchar(255)  NOT NULL,\n",
      "  \"other_details\" varchar(255)  NOT...\n",
      "执行: CREATE TABLE \"business_processes\" (\n",
      "  \"process_id\" INT GENERATED BY DEFAULT AS IDENTITY,\n",
      "  \"next_pro...\n",
      "执行: CREATE TABLE \"process_outcomes\" (\n",
      "  \"process_outcome_code\" char(15)  NOT NULL,\n",
      "  \"process_outcome_de...\n",
      "执行: CREATE TABLE \"process_status\" (\n",
      "  \"process_status_code\" char(15)  NOT NULL,\n",
      "  \"process_status_descri...\n",
      "执行: CREATE TABLE \"ref_staff_roles\" (\n",
      "  \"staff_role_code\" char(15)  NOT NULL,\n",
      "  \"staff_role_description\" ...\n",
      "执行: CREATE TABLE \"staff\" (\n",
      "  \"staff_id\" INT GENERATED BY DEFAULT AS IDENTITY,\n",
      "  \"staff_details\" varchar(...\n",
      "执行: CREATE TABLE \"documents\" (\n",
      "  \"document_id\" INT GENERATED BY DEFAULT AS IDENTITY,\n",
      "  \"author_name\" var...\n",
      "执行: CREATE TABLE \"documents_processes\" (\n",
      "  \"document_id\" int NOT NULL,\n",
      "  \"process_id\" int NOT NULL,\n",
      "  \"p...\n",
      "执行: CREATE TABLE \"staff_in_processes\" (\n",
      "  \"document_id\" int NOT NULL,\n",
      "  \"process_id\" int NOT NULL,\n",
      "  \"st...\n",
      "\n",
      "✅ 所有 SQL 命令在一个事务中成功执行并提交。\n",
      "数据库连接已关闭。\n"
     ]
    }
   ],
   "source": [
    "for i in subdir:\n",
    "    commit(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843d6e07",
   "metadata": {},
   "source": [
    "# 插入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f42ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "\n",
    "def commit2(database):\n",
    "    database = f\"spider1_0_{database}\"\n",
    "    # --- 1. 数据库连接配置 ---\n",
    "    DB_CONFIG = {\n",
    "        \"host\": \"xxx\",\n",
    "        \"database\": database,  # 替换为您的数据库名称\n",
    "        \"user\": \"postgres\",      # 替换为您的用户名\n",
    "        \"password\": \"xxx\",  # 替换为您的密码\n",
    "        \"port\": \"xxx\"               # 默认端口\n",
    "    }\n",
    "\n",
    "    # --- 2. SQL 文件路径 ---\n",
    "    SQL_FILE_PATH = f\"__{database}-data.sql\"  # 替换为您的 SQL 文件路径\n",
    "\n",
    "    def execute_sql_file():\n",
    "        conn = None\n",
    "        try:\n",
    "            # 连接到 PostgreSQL 数据库\n",
    "            print(f\"尝试连接到数据库: {DB_CONFIG['database']}...\")\n",
    "            conn = psycopg2.connect(**DB_CONFIG)\n",
    "            conn.autocommit = False  # 禁用自动提交，以实现事务控制\n",
    "            cursor = conn.cursor()\n",
    "            print(\"连接成功。\")\n",
    "\n",
    "            # 读取 SQL 文件内容\n",
    "            print(f\"读取 SQL 文件: {SQL_FILE_PATH}...\")\n",
    "            with open(SQL_FILE_PATH, 'r', encoding='utf8') as f:\n",
    "                # PostgreSQL 的 psycop2 驱动不能像 MySQL 一样直接处理多条语句\n",
    "                # 我们需要将文件内容拆分成单条命令\n",
    "                sql_commands = f.read()\n",
    "\n",
    "            # 使用 split() 方法按分号 ; 拆分命令，并过滤掉空行\n",
    "            # 注意：这假设您的 SQL 文件中的每条命令都以 ; 结束\n",
    "            commands = [cmd.strip() for cmd in sql_commands.split(';') if cmd.strip()]\n",
    "            print(commands)\n",
    "            print(f\"找到 {len(commands)} 条 SQL 命令，开始执行...\")\n",
    "\n",
    "            # 逐条执行 SQL 命令\n",
    "            for command in commands:\n",
    "                # 过滤掉注释行\n",
    "                if command.upper().startswith('--') or command.upper().startswith('/*'):\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    # 打印正在执行的命令（仅打印前100字符）\n",
    "                    print(f\"执行: {command[:100]}...\")\n",
    "                    cursor.execute(command)\n",
    "                    \n",
    "                except psycopg2.Error as e:\n",
    "                    # 如果某条命令失败，打印错误并继续或中止（取决于需求）\n",
    "                    print(f\"❌ 命令执行失败: {e.diag.message_primary}\")\n",
    "                    # 默认行为：遇到错误则抛出异常，触发 finally 中的回滚\n",
    "\n",
    "            # 提交事务\n",
    "            conn.commit()\n",
    "            print(\"\\n✅ 所有 SQL 命令在一个事务中成功执行并提交。\")\n",
    "\n",
    "        except psycopg2.OperationalError as e:\n",
    "            print(f\"\\n❌ 连接或操作失败: {e}\")\n",
    "            print(\"请检查数据库配置、服务状态和网络连接。\")\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"\\n❌ 错误: 找不到 SQL 文件 {SQL_FILE_PATH}，请检查路径。\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ 发生意外错误: {e}\")\n",
    "            if conn:\n",
    "                conn.rollback()  # 遇到任何错误都回滚事务\n",
    "                print(\"事务已回滚。\")\n",
    "\n",
    "        finally:\n",
    "            # 关闭数据库连接\n",
    "            if conn:\n",
    "                cursor.close()\n",
    "                conn.close()\n",
    "                print(\"数据库连接已关闭。\")\n",
    "\n",
    "\n",
    "    execute_sql_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff42c66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "尝试连接到数据库: spider1_0_cre_doc_workflow...\n",
      "连接成功。\n",
      "读取 SQL 文件: __spider1_0_cre_doc_workflow-data.sql...\n",
      "['INSERT INTO \"authors\" VALUES (\\'Addison Denesik\\',\\'\\'),(\\'Adeline Wolff\\',\\'\\'),(\\'Antwon Krajcik V\\',\\'\\'),(\\'Beverly Bergnaum MD\\',\\'\\'),(\\'Bianka Cummings\\',\\'\\'),(\\'Dr. Dario Hermiston\\',\\'\\'),(\\'Dr. Shad Lowe\\',\\'\\'),(\\'Era Kerluke\\',\\'\\'),(\\'Eveline Bahringer\\',\\'\\'),(\\'Fiona Sipes DVM\\',\\'\\'),(\\'Jameson Konopelski\\',\\'\\'),(\\'Katharina Koepp\\',\\'\\'),(\\'Malvina Metz\\',\\'\\'),(\\'Marjolaine Paucek\\',\\'\\'),(\\'Mr. Joaquin Sanford\\',\\'\\'),(\\'Prof. Baron Heller II\\',\\'\\'),(\\'Shanie Skiles\\',\\'\\'),(\\'Telly Pfannerstill\\',\\'\\'),(\\'Tevin Weber\\',\\'\\'),(\\'Vidal Sanford\\',\\'\\')', 'INSERT INTO \"business_processes\" VALUES (9,9,\\'process\\',\\'normal\\',NULL)', 'INSERT INTO \"process_outcomes\" VALUES (\\'finish\\',\\'finish\\'),(\\'start\\',\\'starting soon\\'),(\\'working\\',\\'working on\\')', 'INSERT INTO \"ref_staff_roles\" VALUES (\\'ED\\',\\'Editor\\'),(\\'HR\\',\\'Human Resource\\'),(\\'MG\\',\\'Manager\\'),(\\'PR\\',\\'Proof Reader\\'),(\\'PT\\',\\'Photo\\')', 'INSERT INTO \"staff\" VALUES (3,\\'Mrs. Aniya Klocko Sr.\\'),(26,\\'Prof. Pietro Hudson\\'),(52,\\'Mr. Sid Hessel\\'),(66,\\'Rosie Conn\\'),(67,\\'Jade O\\'\\'Connell III\\'),(76,\\'Santina Cronin\\'),(93,\\'Bella Hilll DDS\\'),(100,\\'Prof. Porter Dickinson Sr.\\')', 'INSERT INTO \"process_status\" VALUES (\\'ct\\',\\'continue\\'),(\\'pp\\',\\'postpone\\')', 'INSERT INTO \"documents\" VALUES \\n(0,\\'Malvina Metz\\',\\'Travel to Brazil\\',\\'Nulla molestiae voluptas recusandae dolores explicabo et. Consequuntur ut autem velit eos aut.\\',NULL),\\n(4,\\'Telly Pfannerstill\\',\\'Travel to China\\',\\'Maiores suscipit earum sed iure. Quis voluptatem facilis doloremque nisi corrupti. Sed est repellendus et aut id. Nisi quis ex eligendi possimus ut ut unde.\\',NULL),\\n(7,\\'Malvina Metz\\',\\'Travel to England\\',\\'Dolores beatae omnis dolorem laudantium quaerat ut. Perspiciatis explicabo est ut vel porro omnis. Aut non occaecati aut quia ut non omnis. Quia quam ea consequuntur quo aliquam.\\',NULL),\\n(24,\\'Bianka Cummings\\',\\'Travel to Egypt\\',\\'Culpa voluptatibus alias quo amet dolore eum possimus. Qui placeat cumque non aperiam. Cupiditate pariatur dolorum sed ut.\\',NULL),\\n(29,\\'Bianka Cummings\\',\\'Travel to Ireland\\',\\'Cumque a ducimus perferendis sint. Quidem tempora recusandae accusamus possimus aut vitae quo. Omnis earum sint doloribus velit.\\',NULL),\\n(52,\\'Eveline Bahringer\\',\\'How to cook chicken\\',\\'Soluta vitae sed soluta. Aut eos omnis dolorem qui non recusandae neque. Atque enim inventore sint dolor sit.\\',NULL),\\n(77,\\'Marjolaine Paucek\\',\\'How to cook pasta\\',\\'Occaecati id consectetur amet. Fuga vel voluptate qui autem quisquam quis. Eos rerum et iste impedit vel facere.\\',NULL),\\n(79,\\'Tevin Weber\\',\\'How to cook steak\\',\\'Eius rerum rerum architecto optio reprehenderit rerum id. Voluptatem et atque expedita. Voluptatem sint qui aut nostrum voluptas.\\',NULL),\\n(262,\\'Addison Denesik\\',\\'How to cook rice\\',\\'Quo alias nam consectetur nostrum voluptatibus omnis occaecati. Perspiciatis assumenda sed ullam veritatis modi id. Animi praesentium tenetur hic reiciendis nihil hic aut.\\',NULL),\\n(462,\\'Adeline Wolff\\',\\'Learning about flowers\\',\\'Dolor ipsum sed cum aliquid eius enim exercitationem. Eius cupiditate magni sed et. Ex qui debitis sint aliquam illo eligendi magni praesentium. Et reiciendis sed in nostrum eius asperiores. Repellat et odio non qui mollitia.\\',NULL),\\n(927,\\'Tevin Weber\\',\\'Learning about palm reading\\',\\'Omnis perferendis voluptas ea animi ad eum voluptatibus. Tempora natus deleniti consequatur rerum id nisi fugit nihil. Labore repellendus porro consequatur qui.\\',NULL),\\n(435463,\\'Antwon Krajcik V\\',\\'Learning about chess\\',\\'Qui dolor et porro ut commodi error sed. Qui deserunt et est provident ut. Et quos libero iusto qui enim.\\',NULL),\\n(461893,\\'Era Kerluke\\',\\'Learning about society\\',\\'Magnam quos voluptatibus sit qui. Recusandae dignissimos repellendus et dolor sequi provident. Consectetur occaecati illum laboriosam id.\\',NULL),\\n(782065904,\\'Beverly Bergnaum MD\\',\\'Learning about arts\\',\\'Qui omnis sint eligendi adipisci perferendis. Quis id voluptatum nobis sed magnam animi quos. Consequatur voluptates voluptatum iure recusandae.\\',NULL),\\n(948678383,\\'Beverly Bergnaum MD\\',\\'Learning about history\\',\\'Corrupti porro nemo voluptas voluptatibus ipsam minus sed. Alias dolores voluptatibus reprehenderit sunt architecto mollitia incidunt molestiae.\\',NULL)', 'INSERT INTO \"documents_processes\" VALUES \\n(0,9,\\'finish\\',\\'ct\\'),(4,9,\\'start\\',\\'ct\\'),\\n(7,9,\\'start\\',\\'pp\\'),(24,9,\\'start\\',\\'ct\\'),\\n(52,9,\\'finish\\',\\'pp\\'),(462,9,\\'working\\',\\'ct\\'),\\n(927,9,\\'working\\',\\'pp\\'),(435463,9,\\'start\\',\\'ct\\'),\\n(461893,9,\\'finish\\',\\'pp\\'),(782065904,9,\\'working\\',\\'ct\\')', 'INSERT INTO \"staff_in_processes\" VALUES (0,9,3,\\'MG\\',\\'1989-02-06 18:30:52\\',\\'2001-08-10 20:58:06\\',NULL),(0,9,67,\\'ED\\',\\'2015-01-01 06:43:57\\',\\'1982-01-11 19:27:20\\',NULL),(4,9,3,\\'HR\\',\\'1979-10-19 18:36:39\\',\\'1993-12-13 11:55:33\\',NULL),(7,9,100,\\'PT\\',\\'1988-06-20 01:13:16\\',\\'2000-06-15 03:03:57\\',NULL),(24,9,26,\\'PR\\',\\'1973-02-04 06:53:33\\',\\'2005-10-19 08:53:29\\',NULL),(462,9,26,\\'ED\\',\\'1988-08-05 21:55:02\\',\\'1995-03-09 06:54:14\\',NULL),(462,9,76,\\'ED\\',\\'2009-08-07 08:26:16\\',\\'1973-09-18 07:39:56\\',NULL),(927,9,3,\\'ED\\',\\'1998-09-05 17:52:04\\',\\'2014-05-24 01:12:43\\',NULL),(435463,9,52,\\'PT\\',\\'1972-04-24 05:45:56\\',\\'1974-08-02 01:37:15\\',NULL),(461893,9,67,\\'HR\\',\\'2000-06-10 21:41:38\\',\\'2007-02-12 17:11:51\\',NULL),(461893,9,93,\\'MG\\',\\'2010-05-08 11:30:36\\',\\'1973-02-25 01:08:20\\',NULL),(782065904,9,52,\\'ED\\',\\'2007-07-21 13:51:39\\',\\'1970-03-14 11:36:29\\',NULL),(782065904,9,66,\\'MG\\',\\'1983-04-04 06:50:24\\',\\'1996-03-15 15:12:08\\',NULL)']\n",
      "找到 9 条 SQL 命令，开始执行...\n",
      "执行: INSERT INTO \"authors\" VALUES ('Addison Denesik',''),('Adeline Wolff',''),('Antwon Krajcik V',''),('B...\n",
      "执行: INSERT INTO \"business_processes\" VALUES (9,9,'process','normal',NULL)...\n",
      "执行: INSERT INTO \"process_outcomes\" VALUES ('finish','finish'),('start','starting soon'),('working','work...\n",
      "执行: INSERT INTO \"ref_staff_roles\" VALUES ('ED','Editor'),('HR','Human Resource'),('MG','Manager'),('PR',...\n",
      "执行: INSERT INTO \"staff\" VALUES (3,'Mrs. Aniya Klocko Sr.'),(26,'Prof. Pietro Hudson'),(52,'Mr. Sid Hesse...\n",
      "执行: INSERT INTO \"process_status\" VALUES ('ct','continue'),('pp','postpone')...\n",
      "执行: INSERT INTO \"documents\" VALUES \n",
      "(0,'Malvina Metz','Travel to Brazil','Nulla molestiae voluptas recus...\n",
      "执行: INSERT INTO \"documents_processes\" VALUES \n",
      "(0,9,'finish','ct'),(4,9,'start','ct'),\n",
      "(7,9,'start','pp')...\n",
      "执行: INSERT INTO \"staff_in_processes\" VALUES (0,9,3,'MG','1989-02-06 18:30:52','2001-08-10 20:58:06',NULL...\n",
      "\n",
      "✅ 所有 SQL 命令在一个事务中成功执行并提交。\n",
      "数据库连接已关闭。\n"
     ]
    }
   ],
   "source": [
    "for i in subdir:\n",
    "    commit2(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nl2sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
